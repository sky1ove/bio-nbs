[
  {
    "objectID": "sankey_diagram.html",
    "href": "sankey_diagram.html",
    "title": "Sankey diagram",
    "section": "",
    "text": "import numpy as np,pandas as pd\nfrom matplotlib import pyplot as plt\n\nimport plotly.graph_objects as go\nimport plotly.io as pio\n\nimport scipy.stats as stats\nData is a csv/excel file, with H1-H3 columns as control and H4-H6 as experimental file, the value represent RNA level (not know if it is log2 transformed already, but use Avg2/Avg1 for FC)",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#calculate-p-value",
    "href": "sankey_diagram.html#calculate-p-value",
    "title": "Sankey diagram",
    "section": "Calculate p-value",
    "text": "Calculate p-value\n\ndf = pd.read_csv('hong_data.csv',na_values=['#N/A'])\ndf['Gene'] = df['human_gene']\n\n# Remove zero as it affect p value\ndf[['H1', 'H2', 'H3', 'H4', 'H5', 'H6']] = df[['H1', 'H2', 'H3', 'H4', 'H5', 'H6']].replace(0, np.nan)\n\ndf['Control'] = df[['H1','H2','H3']].mean(1)\ndf['Experiment'] = df[['H4','H5','H6']].mean(1)\n\n# Calculate fold change and log fold change\ndf['Fold Change'] = df['Experiment'] / df['Control']\ndf['Log2 Fold Change'] = np.log2(df['Fold Change'])\n\n# Perform t-test between Control and Experiment groups\ncontrol_cols = ['H1', 'H2', 'H3']\nexperiment_cols = ['H4', 'H5', 'H6']\n\n\ndef ttest_row(row):\n    # Extract values from each group and drop NaN values\n    group1 = row[['H1', 'H2', 'H3']].dropna().astype(float)  # Group 1: Drop NaN and convert to float\n    group2 = row[['H4', 'H5', 'H6']].dropna().astype(float)  # Group 2: Drop NaN and convert to float\n\n    # Perform t-test only if both groups have at least 2 values\n    if len(group1) &gt; 1 and len(group2) &gt; 1:\n        t_stat, p_value = stats.ttest_ind(group1, group2, equal_var=False)  # Welch's t-test (unequal variance),which is more robust when the two groups may not have the same variance.\n        return pd.Series({'T-statistic': t_stat, 'P-value': p_value})\n    else:\n        return pd.Series({'T-statistic': np.nan, 'P-value': np.nan})\n\n# Apply the function row-wise\nresult = df.apply(ttest_row, axis=1)\n\n\ndf = pd.concat([df,result],axis=1)\n\n\n# Compute the -log10 of the 'P-value'\ndf['log10_P'] = -np.log10(df['P-value'])\n\n# Assign the sign of 'Log2 Fold Change' to the 'log10_P' values\ndf['signed_log10_P'] = np.sign(df['Log2 Fold Change']) * df['log10_P']\n\n\ndf.to_csv('ttest_processed_zero_exclude.csv',index=False)",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#pathway-analysis",
    "href": "sankey_diagram.html#pathway-analysis",
    "title": "Sankey diagram",
    "section": "Pathway analysis",
    "text": "Pathway analysis\nGet up-regulated genes and down-regulated genes with p-value&lt;0.05; do analysis separately.\nGo to DAVID bioinformatics website, go to Upload –&gt; Step 1: paste gene symbols –&gt; Step2: Official Gene Symbol, select species, if mouse: mus, if human: homo, –&gt; Step3: select Gene List –&gt; Step4: submit.\nClick start analysis, go to GO-BP, click chart, download gene list.\n\n\n\nimage.png",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#optional-plot-gene-expression",
    "href": "sankey_diagram.html#optional-plot-gene-expression",
    "title": "Sankey diagram",
    "section": "(Optional) Plot gene expression",
    "text": "(Optional) Plot gene expression\n\ndf_cleaned = df.dropna(subset=['Fold Change'])  # Drop NaN values\ndf_cleaned = df_cleaned[df_cleaned['Fold Change'] != 0]  # Drop 0 values\ndf_cleaned = df_cleaned[np.isfinite(df_cleaned['Fold Change'])]  # Drop inf and -inf values\n\n\ndf_cleaned['zero'] = 0\n\n\ndf_cleaned = df_cleaned.sort_values('signed_log10_P',ascending=False).reset_index(drop=True)\n\n\ndf_sig = df_cleaned.query('`P-value` &lt;=0.05').copy()\n\n\nplot_sankey(pd.concat([df_sig.head(100),df_sig.tail(100)]),'human_gene','zero','signed_log10_P')",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#sankey-for-pathway-analysis",
    "href": "sankey_diagram.html#sankey-for-pathway-analysis",
    "title": "Sankey diagram",
    "section": "Sankey for pathway analysis",
    "text": "Sankey for pathway analysis\n\ndef plot_sankey(df, gene_col, col1, col2,figsize=(1000,600),write=False,link_colors=None,link_values=None):\n  df = df.copy()\n\n  # Combine control and experiment values into a single array for joint normalization\n  all_values = pd.concat([df[col1], df[col2]])\n\n  # Normalize all values together\n  normalized_values = (all_values - all_values.min()) / (all_values.max() - all_values.min())\n\n  normalized_values = (1-normalized_values)+1e-13\n\n  # Split back into control and experiment\n  df[f'{col1}_norm'] = normalized_values[:len(df)]\n  df[f'{col2}_norm'] = normalized_values[len(df):]\n\n  # Define the source (control) and target (experiment) nodes\n  sources = list(range(len(df)))  # Control nodes (one per gene)\n  targets = list(range(len(df), 2 * len(df)))  # Experiment nodes (one per gene)\n\n  customdata = [[0, orig_y, inv_y] for orig_y, inv_y in zip(df[col1], df[f'{col1}_norm'])] + \\\n              [[0.5, orig_y, inv_y] for orig_y, inv_y in zip(df[col2], df[f'{col2}_norm'])]\n\n  # Create the Sankey diagram with y-axis positions reflecting joint-normalized values and uniform height\n  fig = go.Figure(go.Sankey(\n      arrangement = \"perpendicular\",\n      node=dict(\n          pad=15,\n          thickness=10,  # Uniform thickness for all nodes\n          line=dict(color=\"black\", width=0.5),\n          label=['']*len(df) + df[gene_col].tolist(),  # Labels for control and experiment nodes\n          color=[\"blue\"] * len(df)*2 if not link_colors else link_colors*2,  # Blue for control, green for experiment\n          x=[0.01] * len(df) + [0.99] * len(df),  # Left (x=0) for control, right (x=1) for experiment\n          y=df[f'{col1}_norm'].tolist() + df[f'{col2}_norm'].tolist(),  # Y positions based on joint-normalized values\n          customdata=customdata,\n          hovertemplate='Gene: %{label}&lt;br&gt;Value: %{customdata[1]:.2f}'\n\n      ),\n      link=dict(\n          source=sources,  # Link control nodes to experiment nodes\n          target=targets,\n          value=[0.01]*(len(df)) if not link_values else link_values,  # the expression is relative, changing 1 to 0.1 to all would not change as no variation\n          color=\"rgba(0, 150, 255, 0.5)\" if not link_colors else link_colors # Color of the links\n      )\n  ))\n\n  # Update layout with titles\n  fig.update_layout(\n      title_text=\"Gene Expression Changes\",\n      font_size=10,\n      autosize=False,\n      width=figsize[0],\n      height=figsize[1],\n      margin=dict(r=300)\n  )\n\n  # Save the figure as an HTML file\n  if write:\n    pio.write_html(fig, file=\"sankey_diagram.html\", auto_open=False)\n  # Show the figure\n  fig.show()\n\nFrom the DAVID output csv, pick out important pathways.\n\ndf = pd.read_csv('hong_highlight.csv')\ndf['term'] = df['Term'].str.split('~').str[-1]\ndf['term'] = df['term'].apply(lambda x: x[0].upper() + x[1:] if len(x) &gt; 0 else x)\n\ndf['y_left'] = df.direction.map({'up':0.01,'down':0.99})\ndf['y_right'] = df.direction.map({'up':0.99,'down':0.01})\n\n# fourth value is transparency\ndf['rgba_colors'] = df.direction.map({'up':\"rgba(255, 99, 71, 0.5)\",'down':\"rgba(38, 101, 255, 0.5)\"})\n\nplot_sankey(df,'term',col1='y_left',col2='y_right',figsize=(1000,500),\n            link_colors=df.rgba_colors.tolist(),\n            link_values=df.signed_log10P.abs().tolist(),\n            write=True\n            )",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#bar-plot",
    "href": "sankey_diagram.html#bar-plot",
    "title": "Sankey diagram",
    "section": "Bar plot",
    "text": "Bar plot\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Set the output format to SVG\n\n\ndf = pd.read_csv('hong_highlight.csv')\ndf['term'] = df['Term'].str.split('~').str[-1]\ndf['term'] = df['term'].apply(lambda x: x[0].upper() + x[1:] if len(x) &gt; 0 else x)\n\ndata = df.set_index('term')['signed_log10P'].sort_values()\ncolors = data.apply(lambda x: 'darkred' if x &gt; 0 else 'mediumblue')\n\ndata.plot.barh(color=colors)\nplt.ylabel('')\nplt.xlabel('Signed log10(p-value)')\nplt.title('TAC vs. Vehicle \\n GO Biological Process Pathway Analysis')\nplt.savefig('barplot.svg',bbox_inches='tight')",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "sankey_diagram.html#others",
    "href": "sankey_diagram.html#others",
    "title": "Sankey diagram",
    "section": "Others",
    "text": "Others\n\ndef plot_sankey_multicol(df, columns):\n    df = df.copy()\n    num_col = len(columns)\n    all_values = pd.concat([df[col] for col in columns])\n\n    # Normalize all values together\n    normalized_values = (all_values - all_values.min()) / (all_values.max() - all_values.min())\n\n    # invert the value as html use 0 as highest value\n    normalized_values = 1-normalized_values\n\n    # plotly can't deal with 0 value, so add a small number to 0\n    normalized_values = [i+1e-13 if i ==0 else i for i in normalized_values]\n\n    # Assign normalized values back to DataFrame in new columns\n    for i, col in enumerate(columns):\n        df[col + '_norm'] = normalized_values[i*len(df):(i+1)*len(df)]\n\n    # Prepare data for Sankey diagram\n    nodes = []\n    node_colors = []\n    node_x = []\n    node_y = []\n\n    # Define colors for different conditions\n    colors = ['blue', 'green', 'red', 'purple', 'orange', 'yellow']  # Extend colors as needed\n    position_x = [i/(num_col-1) for i in range(num_col)]  # Positions along x-axis\n    # as it can't deal with 0 effectively, add a small number\n    position_x =[i+1e-13 if i ==0 else i for i in position_x]\n\n    # Create nodes for each condition\n    for i, col in enumerate(columns):\n        nodes.extend(df['Gene'].tolist())\n        node_colors.extend([colors[i % len(colors)]] * len(df))\n\n        node_x.extend([position_x[i]] * len(df))\n        node_y.extend(df[col + '_norm'].tolist())\n\n    # Define source and target indices for links\n    source = []\n    target = []\n    for i in range(num_col - 1):\n\n        source.extend(range(i*len(df), (i+1)*len(df)))\n        target.extend(range((i+1)*len(df), (i+2)*len(df)))\n\n    # Define link properties\n    link_value = [0.1] * (len(source)-1)+[0.1+0.000001]  # All links have a uniform flow size (can be adjusted)\n    link_color = 'rgba(0, 150, 255, 0.5)'  # Link color\n\n    # Create the Sankey diagram\n    fig = go.Figure(go.Sankey(\n        arrangement=\"fixed\",\n        node=dict(\n            pad=15,\n            thickness=20,\n            line=dict(color=\"black\", width=0.5),\n            label=nodes,\n            color=node_colors,\n            x=node_x,\n            y=node_y\n        ),\n        link=dict(\n            source=source,\n            target=target,\n            value=link_value,\n            color=link_color\n        )\n    ))\n\n    # Update layout with titles\n    fig.update_layout(\n        title_text=\"Gene Expression Changes: Control vs Experiment\",\n        font_size=10,\n        autosize=False,\n        width=1000,\n        height=600\n    )\n\n    # Show the figure\n    fig.show()\n\n# Example usage\ndf = pd.DataFrame({\n    'Gene': ['Gene1', 'Gene2', 'Gene3', 'Gene4', 'Gene5', 'Gene6', 'Gene7', 'Gene8', 'Gene9', 'Gene10'],\n    'Control': [1.0]*10,\n    'Experiment1': [2.0]*10,\n    'Experiment2': [3]*9+[1]*1\n})\nplot_sankey_multicol(df, ['Control', 'Experiment1', 'Experiment2'])",
    "crumbs": [
      "Sankey diagram"
    ]
  },
  {
    "objectID": "web_scraper.html",
    "href": "web_scraper.html",
    "title": "Web scraper",
    "section": "",
    "text": "Reference: - YouTube: Add Any Docs to Replit’s AI Chat - Replit: docs2md\n\nimport logging\nimport os\nimport time\nfrom urllib.parse import urlparse\n\nimport treq\nfrom scrapy.crawler import CrawlerProcess\nfrom scrapy.linkextractors import LinkExtractor\nfrom scrapy.spiders import CrawlSpider, Rule\nfrom slugify import slugify\nlogger = logging.getLogger(__name__)\n\nIndicate the doc web, need to have https://docs.. format\n\nDOCS_URL = \"https://docs.fastht.ml\"\n\nGet JINA api token from https://jina.ai/\nScroll down the page, copy API\n\n\n\nimage.png\n\n\n\nos.environ['JINA_API_KEY'] =''\n\n\ndef urljoin(*args):\n  \"\"\"\n  Joins given arguments into an url. Trailing but not leading slashes are\n  stripped for each argument.\n  \"\"\"\n\n  return \"/\".join(map(lambda x: str(x).rstrip('/'), args))\n\n\nclass MarkdownPipeline:\n\n  def create_directory_from_url_with_slug(self, url):\n    parsed_url = urlparse(url)\n    path_segments = parsed_url.path.strip('/').split('/')\n    directory_path = './docs/' + self.collection\n    for segment in path_segments[:-1]:\n      directory_path = os.path.join(directory_path, segment)\n      os.makedirs(directory_path, exist_ok=True)\n    filename = slugify(path_segments[-1])\n    return os.path.join(directory_path, filename)\n\n  def open_spider(self, spider):\n    self.collection = spider.domain.title().replace('.', '')\n    os.makedirs(f'./docs/{self.collection}', exist_ok=True)\n\n  async def process_item(self, item, spider):\n    response = await treq.get('https://r.jina.ai/' + item.get('url'),\n                              headers={\n                                  'Content-Type':\n                                  'text/plain',\n                                  \"Authorization\":\n                                  f\"Bearer {os.environ['JINA_API_KEY']}\"\n                              })\n\n    content = await response.text()\n    url = item.get('url')\n\n    directory = self.create_directory_from_url_with_slug(url)\n\n    with open(directory + '.md', 'w') as f:\n      f.write(content)\n\n    return item\n\n  def close_spider(self, spider):\n    self.client.close()\n\n\nclass PagingIncremental(CrawlSpider):\n  name = \"docs\"\n  custom_settings = {\n      'DOWNLOAD_DELAY': '0',\n      'FEED_EXPORT_ENCODING': 'utf-8',\n      'DEPTH_LIMIT': '0',\n      'AUTOTHROTTLE_ENABLED': 'True',\n      'AUTOTHROTTLE_START_DELAY': '1',\n      'AUTOTHROTTLE_MAX_DELAY': '3',\n      \"AUTOTHROTTLE_TARGET_CONCURRENCY\": '1'\n  }\n  rules = (Rule(LinkExtractor(allow=r\"\"), callback='parse', follow=True), )\n\n  def __init__(self, url, *args, **kwargs):\n    super().__init__(*args, **kwargs)\n    # Visit all found sublinks\n    print(url)\n    self.domain = urlparse(url).hostname\n    self.domain_name = self.domain.split('.')[1]\n    self.allowed_domains = [self.domain]\n\n    self.start_urls = [url]\n\n  def parse(self, response):\n\n    item = {}\n    item[\"url\"] = response.url\n    time.sleep(.1)\n    yield item\n\n\ndef process_docs(url):\n  process = CrawlerProcess({\n      'USER_AGENT': 'Mozilla/5.0',\n      'ITEM_PIPELINES': {\n          '__main__.MarkdownPipeline': 1,\n      },\n  })\n\n  process.crawl(PagingIncremental, url=url)\n  process.start(stop_after_crawl=True)\n\n\nif __name__ == \"__main__\":\n  process_docs(DOCS_URL)\n\nIf in jupyter:\n\nprocess_docs(DOCS_URL)",
    "crumbs": [
      "Web scraper"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "bio-nbs",
    "section": "",
    "text": "Documentation can be found hosted on this GitHub repository’s pages.",
    "crumbs": [
      "bio-nbs"
    ]
  },
  {
    "objectID": "index.html#documentation",
    "href": "index.html#documentation",
    "title": "bio-nbs",
    "section": "",
    "text": "Documentation can be found hosted on this GitHub repository’s pages.",
    "crumbs": [
      "bio-nbs"
    ]
  },
  {
    "objectID": "mpnn_mechanism.html",
    "href": "mpnn_mechanism.html",
    "title": "MPNN study",
    "section": "",
    "text": "!pip install torch_geometric\n\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/63.1 kB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 3.7 MB/s eta 0:00:00\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil&gt;=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\nRequirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (2.4.3)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.3.1)\nRequirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (24.2.0)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.4.1)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (6.1.0)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.16.0)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch_geometric) (3.0.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (2024.8.30)\nRequirement already satisfied: typing-extensions&gt;=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict&lt;7.0,&gt;=4.5-&gt;aiohttp-&gt;torch_geometric) (4.12.2)\nRequirement already satisfied: propcache&gt;=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl&lt;2.0,&gt;=1.12.0-&gt;aiohttp-&gt;torch_geometric) (0.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 29.3 MB/s eta 0:00:00\nInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n\n\n\nimport torch\n\n\ntorch.__version__\n\n'2.5.0+cu121'\n\n\nNow 2.4.0 is available\n\nversion = '2.4.0+cu121'\n\n\nurl = f\"https://data.pyg.org/whl/torch-{version}.html\"\n!pip install torch-scatter -f {url}\n\nLooking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 85.1 MB/s eta 0:00:00\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2+pt24cu121",
    "crumbs": [
      "MPNN study"
    ]
  },
  {
    "objectID": "mpnn_mechanism.html#setup",
    "href": "mpnn_mechanism.html#setup",
    "title": "MPNN study",
    "section": "",
    "text": "!pip install torch_geometric\n\nCollecting torch_geometric\n  Downloading torch_geometric-2.6.1-py3-none-any.whl.metadata (63 kB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/63.1 kB ? eta -:--:--     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 63.1/63.1 kB 3.7 MB/s eta 0:00:00\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.10.10)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2024.6.1)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.4)\nRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.26.4)\nRequirement already satisfied: psutil&gt;=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\nRequirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.2.0)\nRequirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.5)\nRequirement already satisfied: aiohappyeyeballs&gt;=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (2.4.3)\nRequirement already satisfied: aiosignal&gt;=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.3.1)\nRequirement already satisfied: attrs&gt;=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (24.2.0)\nRequirement already satisfied: frozenlist&gt;=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.4.1)\nRequirement already satisfied: multidict&lt;7.0,&gt;=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (6.1.0)\nRequirement already satisfied: yarl&lt;2.0,&gt;=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (1.16.0)\nRequirement already satisfied: async-timeout&lt;5.0,&gt;=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp-&gt;torch_geometric) (4.0.3)\nRequirement already satisfied: MarkupSafe&gt;=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2-&gt;torch_geometric) (3.0.2)\nRequirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (3.4.0)\nRequirement already satisfied: idna&lt;4,&gt;=2.5 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (3.10)\nRequirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (2.2.3)\nRequirement already satisfied: certifi&gt;=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests-&gt;torch_geometric) (2024.8.30)\nRequirement already satisfied: typing-extensions&gt;=4.1.0 in /usr/local/lib/python3.10/dist-packages (from multidict&lt;7.0,&gt;=4.5-&gt;aiohttp-&gt;torch_geometric) (4.12.2)\nRequirement already satisfied: propcache&gt;=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl&lt;2.0,&gt;=1.12.0-&gt;aiohttp-&gt;torch_geometric) (0.2.0)\nDownloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.1/1.1 MB 29.3 MB/s eta 0:00:00\nInstalling collected packages: torch_geometric\nSuccessfully installed torch_geometric-2.6.1\n\n\n\nimport torch\n\n\ntorch.__version__\n\n'2.5.0+cu121'\n\n\nNow 2.4.0 is available\n\nversion = '2.4.0+cu121'\n\n\nurl = f\"https://data.pyg.org/whl/torch-{version}.html\"\n!pip install torch-scatter -f {url}\n\nLooking in links: https://data.pyg.org/whl/torch-2.4.0+cu121.html\nCollecting torch-scatter\n  Downloading https://data.pyg.org/whl/torch-2.4.0%2Bcu121/torch_scatter-2.1.2%2Bpt24cu121-cp310-cp310-linux_x86_64.whl (10.9 MB)\n     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 10.9/10.9 MB 85.1 MB/s eta 0:00:00\nInstalling collected packages: torch-scatter\nSuccessfully installed torch-scatter-2.1.2+pt24cu121",
    "crumbs": [
      "MPNN study"
    ]
  },
  {
    "objectID": "mpnn_mechanism.html#mechanism",
    "href": "mpnn_mechanism.html#mechanism",
    "title": "MPNN study",
    "section": "Mechanism",
    "text": "Mechanism\n\ng = torch.tensor([[0,0,2,3],[1,3,1,1]],dtype=torch.long)\nx = torch.randn(4,3)\nx_e = torch.randn(4,2)\n\ndef message_func(g,x,x_e):\n  src = x[g[0]]\n  dst = x[g[1]]\n  return src\n\nmessage = message_func(g,x,x_e)\n\n\ng = torch.tensor([[0,0,2,3],[1,3,1,1]],dtype=torch.long)\n\n\nx = torch.randn(4,3)\n\n\nx_e = torch.randn(4,2)\n\n\ndef message_func(g,x,x_e):\n  src = x[g[0]]\n  dst = x[g[1]]\n  return src\n\n\nmessage = message_func(g,x,x_e)\n\n\nmessage\n\ntensor([[ 0.2792, -0.3888,  0.9433],\n        [ 0.2792, -0.3888,  0.9433],\n        [ 1.4204,  0.6912,  0.3983],\n        [ 1.2190,  0.1917, -1.3613]])\n\n\n\nx\n\ntensor([[ 0.6476, -0.3849,  0.4243],\n        [-1.2170,  2.3134, -0.0156],\n        [-0.6478, -1.8168, -0.3283],\n        [ 1.6240, -0.1349, -0.9557]])\n\n\n\ndef update_func(x,x_reduce):\n  return x+ x_reduce\n\n\nnew_x = update_func(x,x_reduce)\n\n\nx = torch.tensor([[1],[0.1],[0.01],[0.001]])\n\n\nx\n\ntensor([[1.0000],\n        [0.1000],\n        [0.0100],\n        [0.0010]])\n\n\n\nmessage = message_func(g,x,x_e)\n\n\nmessage\n\ntensor([[1.0000],\n        [1.0000],\n        [0.0100],\n        [0.0010]])\n\n\n\nfrom torch_scatter import scatter\n\n\ndef reduce_func(g,message):\n  return scatter(message,g[1],dim=0, reduce='sum')\n\n\nx_reduce = reduce_func(g,message)\n\n\nmessage\n\ntensor([[ 0.2792, -0.3888,  0.9433],\n        [ 0.2792, -0.3888,  0.9433],\n        [ 1.4204,  0.6912,  0.3983],\n        [ 1.2190,  0.1917, -1.3613]])\n\n\n\ng[1]\n\ntensor([1, 3, 1, 1])\n\n\n\nx_reduce\n\ntensor([[ 0.0000,  0.0000,  0.0000],\n        [ 2.9186,  0.4941, -0.0197],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.2792, -0.3888,  0.9433]])\n\n\n\ng.shape\n\ntorch.Size([2, 4])\n\n\n\ndef get_in_degrees(g):\n  inputs = torch.ones(g.size(1))\n  return scatter(inputs, g[1],reduce='sum')\n\n\ndegrees = get_in_degrees(g)\n\n\ndegrees\n\ntensor([0., 3., 0., 1.])\n\n\n\nfrom torch_geometric.nn.conv import MessagePassing\n\n\nclass GCNLayer(MessagePassing):\n  def __init__(self):\n    super().__init__(aggr='add')\n    self.lin = torch.nn.Linear(2,3)\n\n  def forward(self,g,x): # edge before node feature x\n    print('input node feature',x)\n\n    x = self.lin(x)\n    print('step1, linear trasnform the node features:',x)\n    degrees = get_in_degrees(g)\n    degrees = 1/(torch.pow(degrees,-0.5)+1e-16)\n\n    src_d = degrees[g[0]]\n    dst_d = degrees[g[1]]\n    print('src_d:',src_d,'dst_d:',dst_d)\n    weight = (src_d*dst_d).unsqueeze(1)\n    print('step2 normalized degree:',weight)\n\n    out = self.propagate(g,x=x, weight = weight)\n    print('step5', out)\n\n    return out\n\n  def message(self,x_j, weight): # source j, target i\n    print('step3 get source features:',x_j,'normalized degree:',weight)\n    out = x_j*weight\n    print('step4 normalized source features:',out)\n    return out\n\n\nlayer = GCNLayer()\n\n\nx = torch.randn(4,2)\n\n\nx\n\ntensor([[-2.1208, -0.5321],\n        [-0.4745,  0.9924],\n        [ 0.1378,  0.6422],\n        [-0.6585, -1.2959]])\n\n\n\ng = torch.tensor([[0,0,2,3,1],[1,3,1,1,0]],dtype=torch.long)\n\n\nnew_x = layer(g,x)\n\ninput node feature tensor([[-2.1208, -0.5321],\n        [-0.4745,  0.9924],\n        [ 0.1378,  0.6422],\n        [-0.6585, -1.2959]])\nstep1, linear trasnform the node features: tensor([[ 0.1784, -0.3058,  1.1049],\n        [-1.1339,  0.2926, -0.6656],\n        [-0.9919, -0.0605, -0.6803],\n        [ 0.4678, -1.1036,  1.0191]], grad_fn=&lt;AddmmBackward0&gt;)\nsrc_d: tensor([1.0000, 1.0000, 0.0000, 1.0000, 1.7321]) dst_d: tensor([1.7321, 1.0000, 1.7321, 1.7321, 1.0000])\nstep2 normalized degree: tensor([[1.7321],\n        [1.0000],\n        [0.0000],\n        [1.7321],\n        [1.7321]])\nstep3 get source features: tensor([[ 0.1784, -0.3058,  1.1049],\n        [ 0.1784, -0.3058,  1.1049],\n        [-0.9919, -0.0605, -0.6803],\n        [ 0.4678, -1.1036,  1.0191],\n        [-1.1339,  0.2926, -0.6656]], grad_fn=&lt;IndexSelectBackward0&gt;) normalized degree: tensor([[1.7321],\n        [1.0000],\n        [0.0000],\n        [1.7321],\n        [1.7321]])\nstep4 normalized source features: tensor([[ 0.3089, -0.5296,  1.9138],\n        [ 0.1784, -0.3058,  1.1049],\n        [-0.0000, -0.0000, -0.0000],\n        [ 0.8103, -1.9114,  1.7651],\n        [-1.9640,  0.5068, -1.1529]], grad_fn=&lt;MulBackward0&gt;)\nstep5 tensor([[-1.9640,  0.5068, -1.1529],\n        [ 1.1192, -2.4411,  3.6790],\n        [ 0.0000,  0.0000,  0.0000],\n        [ 0.1784, -0.3058,  1.1049]], grad_fn=&lt;ScatterAddBackward0&gt;)\n\n\n\nimport torch\nfrom torch.nn import Linear, Parameter\nfrom torch_geometric.nn import MessagePassing\nfrom torch_geometric.utils import add_self_loops, degree\n\n\nbias = Parameter(torch.empty(10))\n\n\ntorch.empty?\n\n\nbias\n\nParameter containing:\ntensor([3.0695e+37, 4.3868e-41, 4.6949e+20, 3.2917e-41, 1.0282e-14, 4.3868e-41,\n        5.6391e+20, 3.2917e-41, 0.0000e+00, 0.0000e+00], requires_grad=True)\n\n\n\nclass GCNConv(MessagePassing):\n    def __init__(self, in_channels, out_channels):\n        super().__init__(aggr='add')  # \"Add\" aggregation (Step 5).\n        self.lin = Linear(in_channels, out_channels, bias=False)\n        self.bias = Parameter(torch.empty(out_channels))\n\n        self.reset_parameters()\n\n    def reset_parameters(self):\n        self.lin.reset_parameters()\n        self.bias.data.zero_()\n\n    def forward(self, x, edge_index):\n        # x has shape [N, in_channels]\n        # edge_index has shape [2, E]\n        print('step1',edge_index)\n        # Step 1: Add self-loops to the adjacency matrix.\n        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n        print('step2',edge_index)\n        print('x',x)\n        # Step 2: Linearly transform node feature matrix.\n        x = self.lin(x)\n\n        # Step 3: Compute normalization.\n        row, col = edge_index\n        print('row',row)\n        print('col',col)\n        deg = degree(col, x.size(0), dtype=x.dtype)\n        print('deg',deg)\n\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n        norm2 = (deg_inv_sqrt[row] * deg_inv_sqrt[col]).unsqueeze(1)\n        print('step3 normalize degrees',norm2)\n\n        # Step 4-5: Start propagating messages.\n        out = self.propagate(edge_index, x=x, norm=norm2) #会先把value传递给message，然后运用scatter合并\n        print(' step5 propage:', out)\n\n        # Step 6: Apply a final bias vector.\n        out = out + self.bias\n\n        return out\n\n    def message(self, x_j, norm): # message会分出source j 和target i 以及norm值\n        # x_j has shape [E, out_channels]\n        print('step4 normalize source feature',x_j,'norm:',norm)\n        # Step 4: Normalize node features.\n        return norm * x_j\n\n\nedge_index = g\n\n\nx = torch.randn(4,2)\n\n\nconv = GCNConv(2, 3)\n\n\nout = conv(x, edge_index)\n\nstep1 tensor([[0, 0, 2, 3, 1],\n        [1, 3, 1, 1, 0]])\nstep2 tensor([[0, 0, 2, 3, 1, 0, 1, 2, 3],\n        [1, 3, 1, 1, 0, 0, 1, 2, 3]])\nx tensor([[-2.1208, -0.5321],\n        [-0.4745,  0.9924],\n        [ 0.1378,  0.6422],\n        [-0.6585, -1.2959]])\nrow tensor([0, 0, 2, 3, 1, 0, 1, 2, 3])\ncol tensor([1, 3, 1, 1, 0, 0, 1, 2, 3])\ndeg tensor([2., 4., 1., 2.])\nstep3 normalize degrees tensor([[0.3536],\n        [0.5000],\n        [0.5000],\n        [0.3536],\n        [0.3536],\n        [0.5000],\n        [0.2500],\n        [1.0000],\n        [0.5000]])\nstep4 normalize source feature tensor([[-0.9057, -1.6206,  0.2800],\n        [-0.9057, -1.6206,  0.2800],\n        [ 0.2167,  0.3905,  0.3159],\n        [-0.5749, -1.0340, -0.5348],\n        [ 0.0860,  0.1591,  0.6738],\n        [-0.9057, -1.6206,  0.2800],\n        [ 0.0860,  0.1591,  0.6738],\n        [ 0.2167,  0.3905,  0.3159],\n        [-0.5749, -1.0340, -0.5348]], grad_fn=&lt;IndexSelectBackward0&gt;) norm: tensor([[0.3536],\n        [0.5000],\n        [0.5000],\n        [0.3536],\n        [0.3536],\n        [0.5000],\n        [0.2500],\n        [1.0000],\n        [0.5000]])\n step5 propage: tensor([[-0.4224, -0.7541,  0.3782],\n        [-0.3936, -0.7035,  0.2363],\n        [ 0.2167,  0.3905,  0.3159],\n        [-0.7403, -1.3273, -0.1274]], grad_fn=&lt;ScatterAddBackward0&gt;)",
    "crumbs": [
      "MPNN study"
    ]
  }
]